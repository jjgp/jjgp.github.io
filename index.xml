<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Jason Prasad</title><link>https://jjgp.github.io/</link><description>Recent content on Jason Prasad</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Wed, 30 Mar 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://jjgp.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>A ML dev setup with ngrok and Colab</title><link>https://jjgp.github.io/a-ml-dev-setup-with-ngrok-and-colab/</link><pubDate>Wed, 30 Mar 2022 00:00:00 +0000</pubDate><guid>https://jjgp.github.io/a-ml-dev-setup-with-ngrok-and-colab/</guid><description>&lt;p>As a user of a mac with a M1 chip, I often run into the obstacle of
dependencies without support for the arm64 architecture. It leads to
building the dependency locally, using a container or virtual machine, a
remote instance, or finding another dependency with similar features. For
this reason, I was drawn to the many examples of connecting through SSH to
a Colab instance: &lt;a href="https://github.com/abhishekkrthakur/colabcode">ColabCode&lt;/a>,
&lt;a href="https://github.com/WassimBenzarti/colab-ssh">colab-ssh&lt;/a>, &lt;a href="https://github.com/shawwn/colab-tricks">colab-tricks&lt;/a>.
As an exercise in understanding the previous approaches I decided to implement
a solution myself. The full process has been accumated into &lt;a href="https://github.com/jjgp/colab/blob/main/notebooks/ngrok.ipynb">ngrok.ipynb&lt;/a>.&lt;/p>
&lt;h2 id="a-brief-explanation-of-the-process">A brief explanation of the process&lt;/h2>
&lt;p>Essentially to connect to a Colab instance the browser interface must be used
to configure SSH and a tunneling tool such as &lt;a href="https://ngrok.com/">ngrok&lt;/a>
(or Cloudflare Tunnel). I implemented the SSH server with an authorized key and
used &lt;code>ngrok&lt;/code> to create the TCP tunnel. Afterwards I was able to SSH into the
instance. There was one caveat: when I ran &lt;code>nvidia-smi&lt;/code> I was greeted by the
following error:&lt;/p>
&lt;blockquote>
&lt;p>Failed to initialize NVML: Driver/library version mismatch&lt;/p>
&lt;/blockquote>
&lt;h2 id="in-search-of-environment-variables">In search of environment variables&lt;/h2>
&lt;p>It turns out that in my SSH session was missing environment variables that were
present in Colab&amp;rsquo;s IPython shell that allows &lt;code>nvidia-smi&lt;/code> to function properly.
For example, opening up the terminal in the browser interface or using a cell
to run &lt;code>env&lt;/code> would clarify the missing variables. In fact, when cross-referencing
with how &lt;a href="https://github.com/WassimBenzarti/colab-ssh">colab-ssh&lt;/a> is implemented
it&amp;rsquo;s noticable that some environment file writing is happening behind the scenes
(&lt;a href="https://github.com/WassimBenzarti/colab-ssh/blob/0e495da074a9ded37e09e50b26a15b39eb8a4fb0/colab_ssh/launch_ssh.py#L55">colab_ssh/launch_ssh.py#L55&lt;/a>). Even so, I wanted to know why the environment variables
were missing in SSH or populated in the Colab processes. Even more, I didn&amp;rsquo;t want to rely
on a hardcoded list that may change in the future versions of Colab, CUDA, TensorFlow,
or NVIDIA (although I still sort of arrived at a hardcoded list).&lt;/p>
&lt;p>At first I SSH&amp;rsquo;ed into the Colab instance and thought to check all the profile/rc files:
/etc/profile, /etc/bash.bashrc, ~/.bashrc, ~/.bash_profile. I vaguely knew some of these
files were sourced or not sourced in SSH sessions, interactive, non-interactive, login,
yada yada, and XYZ shells. That being said I&amp;rsquo;m not exactly privy to all the details and
it turns out all the files on the instance were pretty vanilla. Therefore, there was
some other reason my SSH shell missed what Colab shells had.&lt;/p>
&lt;h2 id="inspecting-the-web-client">Inspecting the web client&lt;/h2>
&lt;p>I thought I could get a hint by inspecting the browser interface to figure out how it
interacted with the Colab instance. Perhaps opening the Colab terminal would
communicate with the instance in someway that would narrow my search. The source code
is of coursed minified and obfuscated and the HTML wasn&amp;rsquo;t giving me much. I caught
that the terminal is actually a &lt;code>tmux&lt;/code> session and fun to close out with &lt;em>Ctrl+b&lt;/em>, &lt;em>Ctrl+x&lt;/em>,
and &lt;em>y&lt;/em>.&lt;/p>
&lt;p>Inspecting the network when I open and closed the Colab terminal there was a polling request
to a URL like:&lt;/p>
&lt;blockquote>
&lt;p>&lt;a href="https://colab.research.google.com/tun/m/gpu-t4-s-1xvtxpiyecc2j/tty/?authuser=XXXXXXX&amp;amp;transport=polling&amp;amp;t=XXXXXXX&amp;amp;sid=XXXXXXXXXXXXXXXXXXXX">https://colab.research.google.com/tun/m/gpu-t4-s-1xvtxpiyecc2j/tty/?authuser=XXXXXXX&amp;amp;transport=polling&amp;amp;t=XXXXXXX&amp;amp;sid=XXXXXXXXXXXXXXXXXXXX&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>&amp;hellip;and it returns a response that represents the state of the terminal:&lt;/p>
&lt;pre tabindex="0">&lt;code>117:42[&amp;#34;data&amp;#34;,{&amp;#34;data&amp;#34;:&amp;#34;\u001b[m\u001b[?1003l\u001b[?1006l\u001b[?2004l\u001b[1;1H\u001b[1;13r\u001b[1;11H&amp;#34;,&amp;#34;pause&amp;#34;:true}]320:42[&amp;#34;data&amp;#34;,{&amp;#34;data&amp;#34;:&amp;#34;\u001b[H\u001b[34m\u001b[1m/content\u001b[m#\u001b[K\r\n\u001b[K\r\n\u001b[K\r\n\u001b[K\r\n\u001b[K\r\n\u001b[K\r\n\u001b[K\r\n\u001b[K\r\n\u001b[K\r\n\u001b[K\r\n\u001b[K\r\n\u001b[K\r\n\u001b[37m\u001b[40m[0] 0:bash* \&amp;#34;d325abb1682b\&amp;#34; 21:17 30-Mar-22\u001b[m\u001b[1;11H&amp;#34;,&amp;#34;pause&amp;#34;:true}]88:42[&amp;#34;data&amp;#34;,{&amp;#34;data&amp;#34;:&amp;#34;\u001b[H\u001b[K\u001b[34m\u001b[1m/content\u001b[m# &amp;#34;,&amp;#34;pause&amp;#34;:true}]
&lt;/code>&lt;/pre>&lt;p>A lot of that unicode simply paints the following:&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/3421544/160933923-58ab1cf2-ef91-4d16-84ad-2b120a6dbdd1.png" alt="Colab terminal">&lt;/p>
&lt;p>I did notice that the request contained a &lt;code>/tty/&lt;/code> in the path which stands for terminal. It also has
&lt;code>gpu-t4-s-1xvtxpiyecc2j&lt;/code> which could somehow represent that I was using a specific GPU instance. Otherwise,
there wasn&amp;rsquo;t much more to go on.&lt;/p>
&lt;h2 id="what-exactly-is-running-on-the-colab-instance">What exactly is running on the Colab instance&lt;/h2>
&lt;p>Returning to the actual Colab instance I was SSH&amp;rsquo;ed into, I would often run &lt;code>top&lt;/code> or &lt;code>ps -aux&lt;/code> to see
what was running.&lt;/p>
&lt;pre tabindex="0">&lt;code>USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND
root 1 0.0 0.0 992 4 ? Ss 20:44 0:00 /sbin/docker-init -- /datalab/run.sh
root 8 0.0 0.4 367988 54120 ? Sl 20:44 0:01 /tools/node/bin/node /datalab/web/app.js
root 24 0.0 0.0 35892 4904 ? Ss 20:44 0:00 tail -n +0 -F /root/.config/Google/DriveFS/Logs/dpb.txt /root/.config/Google/DriveFS/Logs/drive_fs.txt
root 36 0.1 0.0 0 0 ? Z 20:44 0:05 [python3] &amp;lt;defunct&amp;gt;
root 37 0.0 0.3 160404 40916 ? S 20:44 0:00 python3 /usr/local/bin/colab-fileshim.py
root 62 0.0 0.4 203824 60388 ? Sl 20:44 0:02 /usr/bin/python3 /usr/local/bin/jupyter-notebook --ip=&amp;#34;172.28.0.2&amp;#34; --port=9000 --FileContentsManager.root_dir=&amp;#34;/&amp;#34; --MappingKernelManager.
root 63 0.0 0.0 708228 10612 ? Sl 20:44 0:02 /usr/local/bin/dap_multiplexer --domain_socket_path=/tmp/debugger_14ltpm10wj
root 80 0.3 0.7 470736 93636 ? Ssl 20:52 0:07 /usr/bin/python3 -m ipykernel_launcher -f /root/.local/share/jupyter/runtime/kernel-cc5cc01e-40d9-48b5-8f7a-10571608b891.json
root 100 0.2 0.1 128408 16144 ? Sl 20:52 0:05 /usr/bin/python3 /usr/local/lib/python3.7/dist-packages/debugpy/adapter --for-server 46787 --host 127.0.0.1 --port 23387 --server-access-
root 117 0.1 0.7 524628 103172 ? Sl 20:52 0:04 node /datalab/web/pyright/pyright-langserver.js --stdio --cancellationReceive=file:cc9b716bb043ca4f062688d92cefdb3df8feac12f9
root 704 0.0 0.0 72304 4076 ? Ss 20:52 0:00 /usr/sbin/sshd
root 753 0.0 0.0 39200 6376 ? S 20:53 0:00 bash
root 755 0.2 0.1 726652 24192 ? Sl 20:53 0:04 ngrok tcp 22 --log ngrok.log --log-format logfmt
root 831 0.0 0.0 55756 5856 ? Ss 20:56 0:00 tmux new-session -A -D -s 0
root 832 0.0 0.0 47656 7200 pts/2 Ss+ 20:56 0:00 -bash
root 1088 0.1 0.0 101560 7068 ? Rs 21:29 0:00 sshd: root@pts/0
root 1099 0.0 0.0 20184 3828 pts/0 Ss 21:29 0:00 -bash
root 1112 0.0 0.0 36080 3268 pts/0 R+ 21:29 0:00 ps -aux
&lt;/code>&lt;/pre>&lt;p>So the instance is certainly a container and the initial process is kicked off by some &lt;code>/datalab/run.sh&lt;/code> that
starts a node &lt;code>/datalab/web/app.js&lt;/code> process. There is a Jupyter/IPython notebook process, dap_multiplexer (which
stands for &amp;ldquo;Debug Adapter Protocol&amp;rdquo; as found in the &lt;code>/datalab/web&lt;/code> files), a &lt;code>colab-fileshim.py&lt;/code> Python process (I think is used for the Colab file browser?), a &lt;a href="https://github.com/microsoft/pyright">pyright&lt;/a> language server, a &lt;a href="https://github.com/microsoft/debugpy">debugpy&lt;/a> process, a &lt;code>tmux&lt;/code> session (hello again), and among others&amp;hellip; I saw all these processes
and thought about what I could debug. The &lt;code>/datalab/web/app.js&lt;/code> seemed like a good place to start.&lt;/p>
&lt;h2 id="debugging-the-datalab-proxy-server">Debugging the datalab proxy server&lt;/h2>
&lt;p>In perusing the &lt;code>/datalab/&lt;/code> folder on the Colab instance it became clear that it was a server that proxied the
Jupyter notebook server and setup a few sockets and the other processes. One of those sockets was found in the source
&lt;code>/datalab/web/socketio_to_pty.js&lt;/code> file. The file implemented a &lt;a href="https://socket.io/">socketio&lt;/a> websocket and a &lt;a href="https://github.com/microsoft/node-pty">node-pty&lt;/a> pseudoterminal. Also in the source was the setup of a &lt;code>tmux&lt;/code> session.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-javascript" data-lang="javascript">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">// /datalab/web/socketio_to_pty.js:53
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">spawnProcess&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#39;tmux&amp;#39;&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">var&lt;/span> &lt;span style="color:#a6e22e">processArgs&lt;/span> &lt;span style="color:#f92672">=&lt;/span> [&lt;span style="color:#e6db74">&amp;#39;new-session&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;-A&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;-D&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;-s&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;0&amp;#39;&lt;/span>];
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">if&lt;/span> (&lt;span style="color:#a6e22e">kernelContainerName&lt;/span> &lt;span style="color:#f92672">!==&lt;/span> &lt;span style="color:#e6db74">&amp;#39;&amp;#39;&lt;/span>) {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">processArgs&lt;/span> &lt;span style="color:#f92672">=&lt;/span> [&lt;span style="color:#e6db74">&amp;#39;exec&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;-it&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;-w&amp;#39;&lt;/span>, &lt;span style="color:#e6db74">&amp;#39;/content&amp;#39;&lt;/span>, &lt;span style="color:#a6e22e">kernelContainerName&lt;/span>, &lt;span style="color:#a6e22e">spawnProcess&lt;/span>].&lt;span style="color:#a6e22e">concat&lt;/span>(&lt;span style="color:#a6e22e">processArgs&lt;/span>);
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">spawnProcess&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#e6db74">&amp;#39;docker&amp;#39;&lt;/span>;
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>}
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#66d9ef">this&lt;/span>.&lt;span style="color:#a6e22e">pty&lt;/span> &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#a6e22e">nodePty&lt;/span>.&lt;span style="color:#a6e22e">spawn&lt;/span>(&lt;span style="color:#a6e22e">spawnProcess&lt;/span>, &lt;span style="color:#a6e22e">processArgs&lt;/span>, {
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">name&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#34;xterm-color&amp;#34;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#a6e22e">cwd&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#e6db74">&amp;#39;./content&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#75715e">// Pass environment variables
&lt;/span>&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#a6e22e">env&lt;/span>&lt;span style="color:#f92672">:&lt;/span> &lt;span style="color:#a6e22e">process&lt;/span>.&lt;span style="color:#a6e22e">env&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>});
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Whenever the Colab terminal is opened in the browser, this code spawns the &lt;code>tmux&lt;/code> session. The spawning of the
psuedoterminal also highlights the passing of environment variables! I decided to debug the running server to
look closer. To do so I sent the user signal to the process (refer to the PID from aboves &lt;code>ps -aux&lt;/code>):&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>kill -USR1 &lt;span style="color:#ae81ff">8&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&amp;hellip;and attached to it with:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>/tools/node/bin/node inspect -p &lt;span style="color:#ae81ff">8&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>In the debugger I set a breakpoint around &lt;code>socketio_to_pty.js:53&lt;/code>.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-sh" data-lang="sh">&lt;span style="display:flex;">&lt;span>debug&amp;gt; setBreakpoint&lt;span style="color:#f92672">(&lt;/span>&lt;span style="color:#e6db74">&amp;#34;socketio_to_pty.js&amp;#34;&lt;/span>, 53&lt;span style="color:#f92672">)&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Then in the browser I opened the Colab terminal which triggered the breakpoint.&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/3421544/160939415-bb533170-8a15-4f72-8bc6-1ad5d42e6117.png" alt="debug breakpoint">&lt;/p>
&lt;p>Printing out the &lt;code>process.env&lt;/code> in the &lt;code>repl&lt;/code> shows the extra environment variables.&lt;/p>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/3421544/160938928-06d1f559-29c9-4f7b-a8ce-91d62ab140a2.png" alt="debug repl">&lt;/p>
&lt;p>With the knowledge about the SSH session, &lt;code>docker-init&lt;/code>, and debugged server I came to the thought that the
environment variables were most likely present from the actual &lt;code>docker run&lt;/code> invocation of the container. This
could be why a new shell would not have the variables whereas a psuedoterminal spawned from
the initial process might.&lt;/p>
&lt;h2 id="deciding-on-the-approach">Deciding on the approach&lt;/h2>
&lt;p>After witnessing how the &lt;code>tmux&lt;/code> session was started for the Colab terminal I decided to mimic it as closely as
possibly in my &lt;a href="https://github.com/jjgp/colab/blob/main/notebooks/ngrok.ipynb">ngrok.ipynb&lt;/a>. To do so I read the
source for how &lt;a href="https://github.com/microsoft/node-pty">node-pty&lt;/a> passed the &lt;code>env&lt;/code> property: &lt;a href="https://github.com/microsoft/node-pty/blob/1674722e1caf3ff4dd52438b70ed68d46af83a6d/src/unixTerminal.ts#L282">src/unixTerminal.ts#L282&lt;/a>
and &lt;a href="https://github.com/microsoft/node-pty/blob/1674722e1caf3ff4dd52438b70ed68d46af83a6d/src/terminal.ts#L197">src/terminal.ts#L197&lt;/a>.
Long story short, I took a rather circuitous path to simply hardcode and pass some environment variables. Anyways, I can now
confidently SSH into a Colab instance and even use my favorite VS Code setup.&lt;/p></description></item><item><title>Setting up a development environment for LLVM</title><link>https://jjgp.github.io/setting-up-a-development-environment-for-llvm/</link><pubDate>Sun, 24 May 2020 15:38:44 +0000</pubDate><guid>https://jjgp.github.io/setting-up-a-development-environment-for-llvm/</guid><description>&lt;p>For my course in &lt;a href="https://omscs.gatech.edu/cs-6340-software-analysis">software analysis&lt;/a> I found the need to assemble a
development environment to streamline my work with LLVM. The setup can be found on GitHub at
&lt;a href="https://github.com/jjgp/llvm-development">jjgp/llvm-development&lt;/a>.&lt;/p>
&lt;p>Briefly, it contains a Dockerfile, VS Code Remote-Containers &lt;code>devcontainer.json&lt;/code>, and the structure for a very simple
LLVM pass.&lt;/p>
&lt;p>The Dockerfile builds and Ubuntu 18.04 image with Clang, LLDB, and LLVM built with debug assertions enabled. This is
necessary to enable the use of the &lt;a href="https://llvm.org/docs/ProgrammersManual.html#the-llvm-debug-macro-and-debug-option">LLVM_DEBUG&lt;/a> macro. Having been my first time building the LLVM toolchain in a Docker
image, I did use &lt;a href="https://github.com/pytorch/pytorch/blob/master/.circleci/docker/common/install_llvm.sh">Pytorch&amp;rsquo;s&lt;/a> CircleCI Dockerfile as a starting point. The image took over a half an hour to build on my 2015 MacBook Pro and
required more memory allotted in the Docker resource settings. Without bumping up the memory, the LLVM build process
would run out of it and emit a failure. The actual built image may be found on dockerhub at
&lt;a href="https://hub.docker.com/repository/docker/jjgp/llvm-development">jjgp/llvm-development&lt;/a>.&lt;/p>
&lt;p>The VS Code &lt;a href="https://code.visualstudio.com/docs/remote/remote-overview">Remote Development extension&lt;/a> pack allows for
development in a container. The jjgp/llvm-development Git repository has a &lt;code>devcontainer.json&lt;/code> that points to the
aforementioned dockerhub image, adds a couple useful VS Code extensions, as well as an additional &lt;code>runArgs&lt;/code>. The
&lt;code>runArgs&lt;/code> allows for the use of LLDB. Without it, there will be an error thrown when attempting to use LLDB to
debug a process such as LLVM&amp;rsquo;s &lt;code>opt&lt;/code> command.&lt;/p>
&lt;p>To run the sample pass in the Git repository simple do the following:&lt;/p>
&lt;pre tabindex="0">&lt;code>mkdir build
cd build
cmake -DCMAKE_BUILD_TYPE=Debug ..
make
&lt;/code>&lt;/pre>&lt;p>Note that passing the &lt;code>-DCMAKE_BUILD_TYPE=Debug&lt;/code> option retains the build symbols for debugging with GDB or LLDB.
The above builds the SamplePass shared object that can be loaded as an LLVM pass with the &lt;code>opt&lt;/code> command. See the
Makefile in the root of the Git repository for an example of how to run the SamplePass.&lt;/p>
&lt;p>To debug the pass do the following from the root of the Git repository:&lt;/p>
&lt;pre tabindex="0">&lt;code>clang -emit-llvm -S -fno-discard-value-names -c -o samples/hello_world.ll samples/hello_world.c
gdb opt
b SamplePass::runOnModule
# Make breakpoint pending on future shared library load? (y or [n]) y
run -load build/SamplePass.so -samplepass -S samples/hello_world.ll -disable-output
&lt;/code>&lt;/pre>&lt;p>Then it should stop at the breakpoint!&lt;/p>
&lt;pre tabindex="0">&lt;code>Breakpoint 1, (anonymous namespace)::SamplePass::runOnModule (this=0x555557d68940, M=...) at /workspaces/llvm-development/src/SamplePass.cpp:13
13 bool modified = false;
(gdb) n
14 LLVM_DEBUG(dbgs() &amp;lt;&amp;lt; &amp;#34;I&amp;#39;m here!\n&amp;#34;);
(gdb) n
15 return modified;
(gdb)
&lt;/code>&lt;/pre></description></item><item><title>Building a PC</title><link>https://jjgp.github.io/building-a-pc/</link><pubDate>Thu, 21 Mar 2019 14:40:45 +0000</pubDate><guid>https://jjgp.github.io/building-a-pc/</guid><description>&lt;p>&lt;img src="https://user-images.githubusercontent.com/3421544/160841542-44168773-99af-4f1f-8b02-bafd8f3e2385.jpg" alt="pc">&lt;/p>
&lt;p>Having read a few posts about building a computer for machine and deep learning
I had become inspired to build one of my own.&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://towardsdatascience.com/build-and-setup-your-own-deep-learning-server-from-scratch-e771dacaa252">Build and Setup Your Own Deep Learning Server From Scratch&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://medium.com/@aragalie/build-your-own-top-spec-remote-access-machine-learning-rig-a-very-detailed-assembly-and-dae0f4011a8f">Build your own top-spec remote-access Machine Learning rig: &amp;hellip;&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://medium.com/the-mission/how-to-build-the-perfect-deep-learning-computer-and-save-thousands-of-dollars-9ec3b2eb4ce2">How to build the perfect Deep Learning Computer and save thousands of dollars&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>Of course there are resources in the wild to utilize GPUs that are either free
or cheap (&lt;a href="https://notebooks.azure.com/">Azure&lt;/a>,
&lt;a href="https://www.paperspace.com/">Paperspace&lt;/a>,
&lt;a href="https://towardsdatascience.com/kaggle-vs-colab-faceoff-which-free-gpu-provider-is-tops-d4f0cd625029">Kaggle, and Colab&lt;/a>),
however, I wanted to experience more than that. I wanted to understand in
greater detail what parts there were and how they went together. I wanted to
know what is involved in setting up remote resources and even enable
development from my Macbook or my iPad Pro with
&lt;a href="https://www.termius.com/">Termius&lt;/a>, &lt;a href="https://github.com/blinksh/blink">Blink&lt;/a>, and &lt;a href="https://juno.sh/">Juno&lt;/a>.&lt;/p>
&lt;h2 id="the-parts">The Parts&lt;/h2>
&lt;ul>
&lt;li>&lt;strong>CPU:&lt;/strong> AMD Threadripper 2950X&lt;/li>
&lt;li>&lt;strong>CPU Cooler:&lt;/strong> Corsair H100i v2&lt;/li>
&lt;li>&lt;strong>Motherboard:&lt;/strong> ASRock X399 Taichi&lt;/li>
&lt;li>&lt;strong>Memory:&lt;/strong> Corsair Vengeance LPX 2 x 16 GB&lt;/li>
&lt;li>&lt;strong>Storage:&lt;/strong> Samsung 960 EVO 500 GB M.2-2280 SSD, Seagate Barracuda 2 TB 3.5&amp;quot; HDD, WD 2 TB 3.5&amp;quot; HDD (repurposed from an external drive)&lt;/li>
&lt;li>&lt;strong>Video Card:&lt;/strong> NVIDIA GeForce RTX 2070&lt;/li>
&lt;li>&lt;strong>Case:&lt;/strong> Corsair Air 540&lt;/li>
&lt;li>&lt;strong>Power Supply:&lt;/strong> Corsair 1000 W 80+ Platinum&lt;/li>
&lt;/ul>
&lt;p>Apart from perusing the aforementioned posts on building machine learning rigs,
&lt;a href="https://pcpartpicker.com/user/jjgp/saved/33ZV6h">PCPartPicker&lt;/a> (links to my
part list) and its compatibility check was perhaps the most informative
resource. My process wasn&amp;rsquo;t very scientific and I even splurged on the CPU. I
did make sure to pick a motherboard, CPU, and PSU could support more GPUs or
other PCIe devices in the future. In researching which GPU to use I defaulted
to the judgment outlined in the following: &lt;a href="https://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/">Which GPU(s) to Get for Deep Learning: &amp;hellip;&lt;/a>&lt;/p>
&lt;p>A few things needed for setup include: a grounding cable, thermal paste,
isopropyl alcohol, and a magnetic screw set. The grounding cable is worn at all
times during assembly. The thermal paste is to facilitate the heat transfer between
the CPU and the cooler. The Corsair H100i v2 came with some thermal paste on
it. I opted to clean that off with isopropyl alcohol and apply the thermal paste I had
bought.&lt;/p>
&lt;h2 id="putting-it-together">Putting it Together&lt;/h2>
&lt;p>The most time consuming part of putting the computer together (from the
perspective of a noob) is gathering the information about assembly. I watched
a lot of YouTube, read blog posts, and reread the manuals. The most
informative video I found (and mentioned in one of the blogs above) is
&lt;a href="https://www.youtube.com/watch?v=83mA2TGNRCU">Fractal Design Define C TG / MSI X399 Gaming Pro Carbon&lt;/a>.
After becoming somewhat familiar with the whole process I began assembly. It
is recommended to assemble the motherboard, CPU, CPU cooler, SSD, and
RAM outside of the case to power it on and inspect for parts that may be DOA.
I just followed the steps in the aformentioned Fractal Design video and forewent
powering it on outside because the parts were swimming in space in the Corsair Air
540 and easy to assemble / disassemble.&lt;/p>
&lt;p>A few tidbits that caused some confusion and specific to this setup are as
follows: The hard drive bays in the Corsair Air 540 took more force than I had
realized to properly attach. The post codes on the Dr. Debug output were at
first esoteric and I had to research the forums (&lt;a href="http://forum.asrock.com/forum_posts.asp?TID=3110&amp;amp;title=dr-debug-display-aa">Dr. Debug display AA&lt;/a>)
and consult the manual. The Taichi BIOS will show the CPU temperature as higher
than it actually is (&lt;a href="http://forum.asrock.com/forum_posts.asp?TID=6912&amp;amp;title=x399-taichi-cpu-temperature">X399 Taichi CPU Temperature&lt;/a>).
The motherboard cables from the case to the power, reset, and LED had triangles
to mark the positive leads.&lt;/p>
&lt;h2 id="the-oses">The OSes&lt;/h2>
&lt;p>As is recommended by the sources I have read and personally, Windows is best
installed first. The Taichi BIOS update software only supports Windows and
having a partition for it serves as a failsafe. To install Windows I created
a UEFI GPT bootable USB with a Windows installer and using Rufus. Since I have a
Mac I had to install Windows through Bootcamp to accomplish this. After
creating the bootable USB, I selected it as the boot media through the Taichi
BIOS and followed the steps to install.&lt;/p>
&lt;p>Once Windows was installed on the Samsung 960 EVO I installed the following
apps for maintenance: &lt;a href="http://www.asrock.com/feature/appshop/">ASRock APP Shop&lt;/a>,
&lt;a href="https://www.amd.com/en/technologies/ryzen-master">AMD RYZEN Master&lt;/a>, and
&lt;a href="https://www.corsair.com/us/en/corsairlink">CORSAIR LINK&lt;/a>. With Windows I
created a partition and a UEFI GPT bootable USB with the Ubuntu installer. To
install I simply chose to boot from the USB from the BIOS and followed the
install steps.&lt;/p>
&lt;h2 id="cuda-install">Cuda Install&lt;/h2>
&lt;p>The CUDA install was perhaps the most frustrating part. Mostly because there is
a lot of information to digest at the &lt;a href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html">NVIDIA CUDA Installation Guide for Linux&lt;/a>
and steps can be unclear such as which option to choose to download the
&lt;a href="https://developer.nvidia.com/cuda-downloads">CUDA Toolkit&lt;/a>.
The most straightforward way to go about it is outlined at the following:
&lt;a href="https://www.pugetsystems.com/labs/hpc/How-To-Install-CUDA-10-together-with-9-2-on-Ubuntu-18-04-with-support-for-NVIDIA-20XX-Turing-GPUs-1236/">How To Install CUDA 10&amp;hellip;&lt;/a>.
In short, it&amp;rsquo;s to download the deb (network) CUDA Toolkit and follow the steps
there. I had tried deb (local) and it just lead to unmet dependency issues.&lt;/p>
&lt;h2 id="remote-access">Remote Access&lt;/h2>
&lt;p>&lt;img src="https://user-images.githubusercontent.com/3421544/160841654-715d2524-0fee-44c3-93d0-c0f753879afa.jpg" alt="pi">&lt;/p>
&lt;p>Most of my use of the PC will be remotely. To facilitate that I set up the
following: &lt;a href="https://help.ubuntu.com/community/WakeOnLan">WakeOnLan&lt;/a>,
&lt;a href="https://help.ubuntu.com/lts/serverguide/openssh-server.html.en">OpenSSH&lt;/a>,
&lt;a href="https://www.realvnc.com/">Real VNC&lt;/a>, and &lt;a href="https://www.noip.com/">No-IP&lt;/a>.
As my router does not support the broadcasting of magic packets to wake the
computer from a nonlocal network, I set up a Raspberry Pi on the local network
to do so. Essentially I can SSH into the Raspberry Pi (even with &lt;a href="https://www.termius.com/">Termius&lt;/a>
on my iPhone) and use &lt;a href="https://www.mkssoftware.com/docs/man1/etherwake.1.asp">etherwake&lt;/a>
to turn on my PC.&lt;/p>
&lt;p>The next things I&amp;rsquo;ve planned for my PC are to setup a development environment
for machine learning!&lt;/p></description></item></channel></rss>